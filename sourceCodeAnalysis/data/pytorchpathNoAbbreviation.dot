strict digraph "" {
accUpdateGradParameters;
accGradParameters;
_backward;
backward;
updateGradInput;
updateOutput;
_initSampleBuffer;
_getBufferSize;
"input.size";
windowNarrow;
"currentOutput.size";
_checkInputDim;
_updateAddBuffer;
_checkInputSize;
__init__;
register_parameter;
forward;
"torch.Size";
reset;
applyToModules;
func;
checkScript;
assertExpected;
TypeError;
run_test;
assertEqual;
"torch.is_tensor";
doit;
assertCompiled;
renorm;
__call__;
_do_test;
cuda;
type;
_apply;
_recompute_captures;
NotImplementedError;
RuntimeError;
modules;
named_modules;
"nn.Sequential";
flatten_parameters;
parameters;
"module.parameters";
_makeContiguous;
"input.new";
_viewWeight;
"gradWeight.view";
_unviewWeight;
"input.dim";
_getPositiveDimension;
_get_dim;
_assertInput;
"weight.size";
_init;
"weight.new";
"gradOutput.new";
"_gradOutput.resize_as_";
validateParameters;
"gradOutput.is_contiguous";
_makeInputContiguous;
"input.type";
"input.select";
extend;
remove_from;
read_function;
read;
read_object;
read_string;
read_int;
_read;
"f.read";
Variable;
_test_with_size;
"torch.nn.Conv2d";
"{}'.format";
_lazyInit;
"torch.LongTensor";
"output.type";
add;
"torch.DoubleStorage";
"torch.arange";
wrap_declarations;
generate_wrapper;
generate_option;
map_selected_arguments;
"output.new";
assertExpectedTrace;
process_native;
process_option;
emit_body;
handle_zero_dim;
get_zero_dim_dispatch_when_scalar;
"option.get";
handle_only_zero_dim;
_analytical_jacobian;
"output.nelement";
_slow_forward;
"torch.no_grad";
test_zeros;
_test_zeros;
_gen_sparse;
assert_uncoalesced;
safeCoalesce;
test_zeros_like;
_test_zeros_like;
_assertInputGradOutput;
_checkOutputSize;
"weight.view";
"gradOutput.size";
"input[0].size";
"input.is_same_size";
"input[0].new";
"torch.mul";
"1).expand_as";
"torch.sum";
"input.view";
"torch.mv";
"targetTensor.dim";
"targetTensor.size";
_calculateAdj;
"_repeat.mul_";
"_repeat2.resize_as_";
"gradOutput.narrow";
_iter_with_prev;
backwardUpdate;
read_number;
read_double;
read_boolean;
read_table;
accUpdateGradParameters -> accGradParameters;
accGradParameters -> _backward;
accGradParameters -> _assertInputGradOutput;
accGradParameters -> _checkInputSize;
accGradParameters -> _checkOutputSize;
accGradParameters -> _updateAddBuffer;
accGradParameters -> _makeContiguous;
accGradParameters -> _viewWeight;
accGradParameters -> _unviewWeight;
accGradParameters -> windowNarrow;
accGradParameters -> _init;
_backward -> backward;
_backward -> updateOutput;
backward -> updateGradInput;
backward -> accGradParameters;
backward -> _backward;
backward -> windowNarrow;
updateGradInput -> updateOutput;
updateGradInput -> _backward;
updateGradInput -> windowNarrow;
updateGradInput -> _checkInputSize;
updateGradInput -> _makeContiguous;
updateGradInput -> _viewWeight;
updateGradInput -> _unviewWeight;
updateGradInput -> _getPositiveDimension;
updateGradInput -> _get_dim;
updateGradInput -> _assertInputGradOutput;
updateGradInput -> _init;
updateGradInput -> _checkOutputSize;
updateGradInput -> validateParameters;
updateGradInput -> "gradOutput.narrow";
updateGradInput -> "currentOutput.size";
updateGradInput -> "input.size";
updateGradInput -> "input.select";
updateGradInput -> _iter_with_prev;
updateOutput -> _initSampleBuffer;
updateOutput -> windowNarrow;
updateOutput -> _checkInputDim;
updateOutput -> _updateAddBuffer;
updateOutput -> _checkInputSize;
updateOutput -> renorm;
updateOutput -> _makeContiguous;
updateOutput -> _viewWeight;
updateOutput -> _unviewWeight;
updateOutput -> _getPositiveDimension;
updateOutput -> _get_dim;
updateOutput -> _assertInput;
updateOutput -> _init;
updateOutput -> validateParameters;
updateOutput -> _makeInputContiguous;
updateOutput -> "currentOutput.size";
updateOutput -> "input.size";
updateOutput -> "input.select";
updateOutput -> _lazyInit;
updateOutput -> "output.nelement";
updateOutput -> "input.is_same_size";
updateOutput -> "input[0].new";
updateOutput -> "torch.mul";
updateOutput -> "1).expand_as";
updateOutput -> "input.new";
updateOutput -> "torch.sum";
updateOutput -> "input.dim";
updateOutput -> "weight.size";
updateOutput -> "weight.new";
updateOutput -> "input.view";
updateOutput -> RuntimeError;
updateOutput -> "torch.mv";
updateOutput -> "targetTensor.dim";
updateOutput -> "targetTensor.size";
updateOutput -> "input.type";
updateOutput -> _calculateAdj;
updateOutput -> "_repeat.mul_";
updateOutput -> "_repeat2.resize_as_";
_initSampleBuffer -> _getBufferSize;
_initSampleBuffer -> "input.new";
_getBufferSize -> "input.size";
_getBufferSize -> "torch.Size";
windowNarrow -> "currentOutput.size";
_checkInputDim -> "input.size";
_checkInputDim -> "input.dim";
_checkInputDim -> RuntimeError;
_checkInputDim -> "{}'.format";
_updateAddBuffer -> "input.size";
_updateAddBuffer -> "input.new";
_checkInputSize -> "input.size";
_checkInputSize -> RuntimeError;
__init__ -> register_parameter;
__init__ -> reset;
__init__ -> wrap_declarations;
register_parameter -> forward;
forward -> updateOutput;
forward -> func;
forward -> doit;
forward -> assertExpectedTrace;
forward -> assertCompiled;
reset -> applyToModules;
applyToModules -> func;
func -> checkScript;
func -> run_test;
func -> _test_with_size;
func -> add;
func -> assertEqual;
checkScript -> assertExpected;
checkScript -> assertEqual;
assertExpected -> TypeError;
run_test -> assertEqual;
run_test -> Variable;
run_test -> "torch.nn.Conv2d";
run_test -> "torch.arange";
assertEqual -> "torch.is_tensor";
doit -> assertCompiled;
doit -> assertExpected;
doit -> assertEqual;
assertCompiled -> assertEqual;
renorm -> assertEqual;
renorm -> RuntimeError;
__call__ -> _do_test;
__call__ -> _slow_forward;
_do_test -> cuda;
cuda -> type;
cuda -> _apply;
type -> _apply;
_apply -> _recompute_captures;
_apply -> modules;
_apply -> flatten_parameters;
_recompute_captures -> NotImplementedError;
_recompute_captures -> RuntimeError;
modules -> named_modules;
modules -> "nn.Sequential";
named_modules -> "nn.Sequential";
flatten_parameters -> parameters;
flatten_parameters -> "torch.no_grad";
parameters -> "module.parameters";
_makeContiguous -> "input.new";
_makeContiguous -> "gradOutput.new";
_makeContiguous -> "_gradOutput.resize_as_";
_makeContiguous -> "gradOutput.is_contiguous";
_viewWeight -> "gradWeight.view";
_viewWeight -> "weight.view";
_unviewWeight -> "gradWeight.view";
_unviewWeight -> "weight.view";
_getPositiveDimension -> "input.dim";
_get_dim -> "input.dim";
_assertInput -> "weight.size";
_assertInput -> RuntimeError;
_assertInput -> "torch.is_tensor";
_init -> "weight.new";
validateParameters -> RuntimeError;
_makeInputContiguous -> "input.type";
extend -> register_parameter;
remove_from -> register_parameter;
read_function -> read;
read -> read_object;
read -> read_number;
read -> read_boolean;
read -> read_string;
read -> read_table;
read_object -> read_string;
read_string -> read_int;
read_int -> _read;
_read -> "f.read";
_test_with_size -> Variable;
_lazyInit -> "torch.LongTensor";
_lazyInit -> "output.type";
_lazyInit -> "output.new";
add -> "torch.DoubleStorage";
wrap_declarations -> generate_wrapper;
generate_wrapper -> generate_option;
generate_option -> map_selected_arguments;
map_selected_arguments -> RuntimeError;
assertExpectedTrace -> assertExpected;
process_native -> process_option;
process_option -> emit_body;
emit_body -> handle_zero_dim;
emit_body -> handle_only_zero_dim;
handle_zero_dim -> get_zero_dim_dispatch_when_scalar;
get_zero_dim_dispatch_when_scalar -> "option.get";
handle_only_zero_dim -> get_zero_dim_dispatch_when_scalar;
_analytical_jacobian -> _backward;
_slow_forward -> forward;
test_zeros -> _test_zeros;
_test_zeros -> _gen_sparse;
_gen_sparse -> assert_uncoalesced;
assert_uncoalesced -> safeCoalesce;
safeCoalesce -> assertEqual;
test_zeros_like -> _test_zeros_like;
_test_zeros_like -> _gen_sparse;
_assertInputGradOutput -> RuntimeError;
_assertInputGradOutput -> "weight.size";
_assertInputGradOutput -> "gradOutput.size";
_assertInputGradOutput -> "input[0].size";
_checkOutputSize -> RuntimeError;
backwardUpdate -> accUpdateGradParameters;
read_number -> read_double;
read_double -> _read;
read_boolean -> read_int;
read_table -> read_int;
}
